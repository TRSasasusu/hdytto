import re
import tokenize

from .util import Token

# `comment` uses regex because indent cannot be restored from dedent generated by tokenize.
def comment(stream):
    return re.sub(r'(\'[^\']*\'|\"[^\"]*\"|\/\*[^\/*]*\*\/)', lambda x: x.group(0) if x.group(0)[0] != '/' else '', stream)
